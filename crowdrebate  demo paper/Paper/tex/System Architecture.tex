\section{System Architecture}

Figure~\ref{fig:ar} depicts the architecture of Crowdrebate platform. The user interface module runs on the client-side, enabling both general users and merchant users to get corresponding services. The other three core modules, process automation, crowdrebate algorithm~\cite{Report}, and recommendation system, run on the server host and provide support for the core functionalities in Crowdrebate. We introduce the technical details of these modules in the rest part of this section.

\subsection{User Interface}

There are two types of users interacting with the user interface module, ``general users'' and ``merchant users''. General users, who seek group buying to meet the threshold of rebates, can request and track their orders with the interface while getting a personalized recommendation. Merchant users from online shopping platforms can benefit from the data dashboard to gain a better understanding of user portraits. This module consists of the following four functions.

\subsubsection{Order Requesting}

Users can post their requirements on Crowdrebate with this order requesting function. The input consists of two parts, product information, and customer information. The former includes the shopping platform, product link, and promotion type, which help the web crawlers to target the specific item and its promotions. The critical part is expected time slots and delivery addresses, impacting the rounds and delivery costs for the crowdrebate algorithm to run.

\subsubsection{Order Tracking}

The order tracking function enables users to manage all historical orders. Crowdrebate platform utilizes the web crawler, the crowdrebate algorithm, and the order bot to automate the process of group order and updates data timely for users to track.
	
\subsubsection{Item Recommendation}

Crowdrebate has top coupons and recommended products on the home page, where all users share the same information of top coupons while the recommended products are personalized. Both features are fed with data from Crowdrebate.

\subsubsection{Dashboard Visualization}

Crowdrebate opens API and provides a visualized data dashboard to cooperating online shopping platforms. With the visualized dashboard, merchant users can access to internal data depicting user portraits, product sales, and coupon popularity.

\subsection{Crowdrebate Algorithm}

Crowdrebate algorithm~\cite{Report} can place orders for users' best interests and works as one of the most crucial components in our platform. Considering the combination of coupons and delivery costs, Crowdrebate proposed two algorithms, the order-first algorithm and the delivery-first algorithm, to adapt to different scenarios. Users can freely choose from these algorithms which best fits their needs, and their requests will wait in two pools to process separately.

\textbf{The Order-First Algorithm.} In most cases, coupons with strict thresholds usually guarantee tempting rebates that should way cover the delivery costs. Under such a scenario, we propose the order-first algorithm to place orders. Generally speaking, this algorithm greedily packs orders for a maximum amount of total rebates while ignoring delivery costs. For each coupon, we traverse requests in the eligible pool and calculate the differential rebate amount when compared to placing an order separately, and the request with the largest amount will be integrated into one order until for any request the differential rebate amount fails to increase. However, the number of coupons used in a newly merged order may exceed the upper limit since their amounts are calculated separately before the merger. We introduce \emph{dif procedure} to tackle extra coupons while computing for the differential rebate. After packing requests, we need to place the order and assign one single address as the delivery destination. While this algorithm doesn't take the delivery into account before, it assigns a warehouse to the order to minimize the cost of delivery now.

\textbf{The Warehouse-First Algorithm.} The order-first algorithm performs well in most cases; however, it still suffers from two drawbacks. The first one is due to its lack of consideration for delivery costs, and once the delivery cost gets much higher, this algorithm performs poorly. The second defect results from the time complexity introduced by the error correction dif procedure, which can be fatal when handling peak shopping festival traffic. As a result, a more efficient approach, the warehouse-first algorithm, is proposed to tackle the large scale data and non-negligible delivery costs. Instead of directly combining requests for higher rebates, we first group those requests sharing the same warehouse. Only then will we merge requests within the same warehouse for higher rebates. The preprocessing procedure divides the integral data set into smaller groups to constrain the batch size and running time, and grouping by delivery destination guarantees relatively small delivery costs. Basically, the warehouse-first algorithm is more efficient and can produce a better result for higher delivery costs, while the order-first algorithm stands out when rebates are profitable enough to cover delivery costs. Before users can freely choose from algorithms above, we run the order-first algorithm compulsorily for the cold start since the scale of requests is too small to be split and should handle the higher time complexity while bringing users more rebates.

\subsection{Process Automation}

Crowdrebate uses the process automation module to complete the whole procedure from picking items to pay for our server's orders. Basically, the module comprises two sub-modules, the web crawler retrieving the information of products and coupons, and the order bot to automatically place an order. 

\textbf{The Web Crawler.} Currently, two types of information will be crawled, respectively, products and coupons. For the product information, this module retrieves the data passively. Before the user can post a request, a URL linked to the product must be provided to activate the web crawler. With the pasted URL, the spider bot crawls the associated coupons along with the product information and will specifically return options like size or color for the user to choose. Besides, we crawl all the metadata of this product for further recommendation function. For the coupon information, this module actively seeks data. We take the initiative to crawl information from coupon websites like Etao~\cite{etao} to enrich our available coupon pools. 

\textbf{The Order Bot.} The crowdrebate algorithm runs in rounds periodically and produces final grouped orders each round. Therefore we develop the order bot to handle those orders automatically. Since some exclusive coupons in different orders may violate each other, we introduce multiple accounts to place those exclusive orders, enabling us to run the scripts in parallel.

\subsection{Recommendation System}

The recommendation system module is one of the critical features of Crowdrebate. Considering the online shopping scenario, there will not be a massive change for items on sale. The similarity of items is relatively stable to the user’s interest, so we adapt the item-based collaborative filtering~\cite{sarwar2001item} to recommend similar products. The recommendation system is built upon metadata from the web crawler and users’ historical requests and ratings. Since users on Crowdrebate pursue higher rebates, we improved the algorithm to rank on rebate amounts instead of similarities to meet their demands better. 